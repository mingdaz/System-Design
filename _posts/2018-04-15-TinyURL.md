---
layout: post
title:  "TinyURL"
date:   2018-04-15 08:00:00
categories: DS SNAKE
tags: [ Consistent Hashing, CAP,  ]
---

### Question Description
Please design a service like [TinyURL](https://tinyurl.com/), a URL shortening service, a web service that provides short aliases for redirection of long URLs.

### S: Scenario
Long URL to short URL and reversed.

### N: Necessary(constrain/hypothesis)
Twitter has about 300M active users per month. Let's assume we are 10% popular as Twitter and each user generates 1 shortened URL per day. This leads to 30M service calls per month (1M calls/day). If we are going to keep our service for 5 years, our service will generate about 1.8B records.

1. QPS (queries per second)
- Daily User: 300M/30 = 10M
- Daily usage per person: (Write) long2short 1, (Read) short2long 10
- Daily request: Write 10M, Read 100M
- QPS: Since a day is 86400s approximately 100K. `Write 100, Read 1K`
 - Peak QPS: `Write 200, Read 2K` (Thousand level can be handled by a single SSD MySQL Machine)

2. Storage
- 10M new mappings (long URL to short URL) per day 
- assume each mapping takes 200B in average 
- 2GB every day. 
- 1 TB hard drive could stand for 1.5 years.<br />
Storage is not the problem for this kind of system. Service like Netflix may have storage issues.

Through SN analysis, we could have a big picture of the system. In general, this system is not hard and could be handled by a single SSD Machine.

### A: Application(service/algorithm)
Only one service: URLService

1. Core (Business Logic) Layer:
- Class: URLService
- Interface:
- URLService.encode(String long_url)
- URLService.decode(String short_url)

2. Web Layer:
* REST API:
* GET: /{short_url}, return a http redirect response(301)
* POST: goo.gl method - google shorten URL<br/>
	Request Body: {url=longUrl} e.g. {"longUrl": "http://www.google.com/"}<br/>
	Return OK(200), short_url is included in the data

### K: Kilobit(Data Access)
1. Pick a storage structure: SQL vs NoSQL?<br/>
* Q: Does it need to support transactions? NoSQL does not support transaction.<br/>
**A: No -> NoSQL**
* Do we need rich SQL query? NoSQL does not support as many queries as SQL.<br/>
**A: Not high. -> SQL**
* Pursue development efficiency? Most Web Framework supports SQL database very well (with ORM). It means fewer codes for the system.<br/>
**A: Doesn't matter because there are only a few codes. -> NoSQL**
* Do we need to use AUTO_INCREMENT ID? NoSQL couldn't do this. It only has a global unique Object_id.<br/>
**A: Our algorithm needs AUTO_INCREMENT ID. -> SQL**
* Does the system has a high requirement for QPS? NoSQL has high performance. For example, Memcached's QPS could reach million level, MondoDB  does 10K level, MySQL only supports K level.<br/>
**A: Write 200, Read 2K. Not high. -> SQL**
* How high is the system's scalability? SQL requires developers write their codes to scale, while NoSQL comes with them (sharding, replica).<br/>
**A: Not high. -> SQL**

2. System Algorithm
OK, let's talk about the system algorithm. There are following solutions:
- **Hash function**: long_url -> md5/sha1<br/>
md5 convert a string into 128 binary bits, generally represented as 16 bytes hex:
`http://site.douban.com/chuan -> c93a360dc7f3eb093ab6e304db516653`<br/>
sha1 convert a string into 160 binary bits, generally represented as 20 bytes hex:
`http://site.douban.com/chuan -> dff85871a72c73c3eae09e39ffe97aea63047094`<br/>
These two algorithms could make sure hash values are randomly distributed, but the conflicts are inevitable. Any hash algorithm could have inevitable conflicts.
Pros: Simple. We could take the first 6 chars of the converted string.
Cons: Conflicts.
Solutions: 1. use (long_url + timestamp) as the hash function key. 2. When conflicts, regenerates the hash value(it's different because timestamp changes).
Overall, when urls are over 1 billion, there would be a lot of conflicts and the efficiency could be very low.
- **base62**<br/>
Take short_url as a 62 base notation. 6 bits could represent 62^6=57 billion.
Each short_url represent a decimal digit. It could be the auto_increment_id in SQL database.	
	
	```java
	{% include src/tinyurl/URLService.java %}	
	```
3. Database Schema One table (id, long_url). id is the primary key, ordered by long_url

The basic system architecture:

```Browser <-> Web <-> Core <-> DB```

### E: Evolve(optimize)
Q: How to improve the response speed?

- Improve the response speed between web server and database. Use Memcached to improve response speed. When getting long_url, search in the cache first, then database. We could put 90% read request on the cache.
- Improve the response speed between web server and user's browser Different locations use different web server and cache server. All the areas share a DB used to match the users to the closest web server (through DNS) when they have a miss on the cache.

Q: What if we need one more MySQL machine? 

Issues:
+ running out of cache
+ More and more write requests
+ More and more cache misses

Solutions: Database Partitioning

1. Vertical Partitioning
2. Horizontal sharding

The best way is horizontal sharding.
Currently table structure is (id, long_url). So, which column should be sharding key?<br/>
An easy way is id modulo sharding.
Here comes another question: How could multiple machines share a global auto_increment_id?

Two ways: 
1. use one more machine to maintain the id. 
2. use zookeeper.

Both suck.
So, we do not use global auto_increment_id.

The pro way is put the sharding key as the first byte of the short_url. The idea is simple, get a hash code from original URL and go to corresponding machine then use the same process as a single machine. For routing to the correct node in cluster, Consistent Hashing is commonly used. Use consistent hashing to break the cycle into 62 pieces. It doesn't matter how many pieces because there probably would not be over 62 machines (it could be 360 or whatever). Each machine is responsible for the service in the part of the cycle.

Following is the pseudo code for example,<br>

**Get shortened URL**
+ hash original URL string to 1 digits(in base62) as hashed value `hash_val`
+ use `hash_val` to locate machine on the ring
+ insert original URL into the database and use getShortURL function to get shortened URL `short_url`
+ Combine `hash_val` and `short_url` as our `final_short_url` (length=7) and return to the user

**Retrieve original from short URL**
+ get first char in `final_short_url` as `hash_val`
+ use `hash_val` to locate the machine
+ find the row in the table by rest of 6 chars in `final_short_url` as `short_url`
+ return `original_url` to the user

Each time we add a new machine, put half of the range of the most used machine to the new machine.

**More Optimization**<br>
Put Chinese DB in China, American DB in the United States. Use geographical information as the sharding key, e.g. 0 for Chinese websites, 1 for American websites.
